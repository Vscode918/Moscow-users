{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-asV1Kvjl3av",
        "outputId": "8541416b-1f43-4bcc-f06b-74e5a1745a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched page 1: 100 users.\n",
            "Fetched page 2: 100 users.\n",
            "Fetched page 3: 100 users.\n",
            "Fetched page 4: 100 users.\n",
            "Fetched page 5: 58 users.\n",
            "Total users fetched: 458.\n",
            "Saved 458 users to users.csv and 10563 repositories to repositories.csv.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub API setup\n",
        "GITHUB_TOKEN = \"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\"  # Replace with your GitHub token\n",
        "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
        "\n",
        "# Step 1: Search for users in Moscow with >50 followers\n",
        "def fetch_users():\n",
        "    url = \"https://api.github.com/search/users\"\n",
        "    params = {\"q\": \"location:Moscow followers:>50\", \"per_page\": 100}  # Request 100 per page\n",
        "    users = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        params[\"page\"] = page\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            fetched_users = response.json().get(\"items\", [])\n",
        "            if not fetched_users:\n",
        "                break  # Exit loop if no more users are fetched\n",
        "\n",
        "            users.extend(fetched_users)\n",
        "            print(f\"Fetched page {page}: {len(fetched_users)} users.\")\n",
        "            page += 1\n",
        "        else:\n",
        "            print(f\"Failed to fetch users: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Total users fetched: {len(users)}.\")\n",
        "    return [user[\"login\"] for user in users]\n",
        "\n",
        "# Step 2: Get user details\n",
        "def get_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Clean company name\n",
        "    company = data.get(\"company\", \"\")\n",
        "    if company:\n",
        "        company = company.replace(\"@\", \"\").strip().upper()\n",
        "\n",
        "    # Prepare user details using the SAME values as in the API response\n",
        "    return {\n",
        "        \"login\": data.get(\"login\", \"\"),\n",
        "        \"name\": data.get(\"name\", \"\"),\n",
        "        \"company\": company,\n",
        "        \"location\": data.get(\"location\", \"\"),\n",
        "        \"email\": data.get(\"email\", \"\"),\n",
        "        \"hireable\": str(data.get(\"hireable\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "        \"bio\": data.get(\"bio\", \"\"),\n",
        "        \"public_repos\": data.get(\"public_repos\", 0),\n",
        "        \"followers\": data.get(\"followers\", 0),\n",
        "        \"following\": data.get(\"following\", 0),\n",
        "        \"created_at\": data.get(\"created_at\", \"\")\n",
        "    }\n",
        "\n",
        "# Step 3: Fetch user repositories\n",
        "def get_user_repos(username):\n",
        "    url = f\"https://api.github.com/users/{username}/repos\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    repos = response.json()[:500]  # Limit to 500 repos\n",
        "\n",
        "    repo_data = []\n",
        "    for repo in repos:\n",
        "        repo_data.append({\n",
        "            \"login\": username,  # User's login\n",
        "            \"full_name\": repo.get(\"full_name\", \"\"),\n",
        "            \"created_at\": repo.get(\"created_at\", \"\"),\n",
        "            \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
        "            \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
        "            \"language\": repo.get(\"language\", \"\"),\n",
        "            \"has_projects\": str(repo.get(\"has_projects\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"has_wiki\": str(repo.get(\"has_wiki\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"license_name\": repo.get(\"license\", {}).get(\"key\", \"\") if repo.get(\"license\") is not None else \"\"\n",
        "        })\n",
        "\n",
        "    return repo_data\n",
        "\n",
        "# Step 4: Save data to CSV files\n",
        "def save_to_csv(users, repos):\n",
        "    users_df = pd.DataFrame(users)\n",
        "    repos_df = pd.DataFrame(repos)\n",
        "\n",
        "    # Replace None with empty string for all string columns in users_df and repos_df\n",
        "    users_df.fillna(\"\", inplace=True)\n",
        "    repos_df.fillna(\"\", inplace=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    users_df.to_csv(\"users.csv\", index=False)\n",
        "    repos_df.to_csv(\"repositories.csv\", index=False)\n",
        "    print(f\"Saved {len(users)} users to users.csv and {len(repos)} repositories to repositories.csv.\")\n",
        "\n",
        "# Step 5: Create README.md\n",
        "def create_readme():\n",
        "    with open(\"README.md\", \"w\") as f:\n",
        "        f.write(\"- Data on GitHub users in Moscow with over 50 followers was scraped via GitHub API.\\n\")\n",
        "        f.write(\"- Analyzing the data showed an unexpectedly high number of JavaScript repositories.\\n\")\n",
        "        f.write(\"- Developers should consider making their projects hireable to attract more followers.\\n\")\n",
        "        f.write(\"\\n## About This Project\\n\")\n",
        "        f.write(\"This project collects data on GitHub users in Moscow who have over 50 followers and provides insights into their repositories, programming languages, and affiliations. This analysis helps uncover trends among active GitHub users in the region.\\n\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    users_data = []\n",
        "    repos_data = []\n",
        "\n",
        "    # Fetch users and details\n",
        "    usernames = fetch_users()\n",
        "    for username in usernames:\n",
        "        user_details = get_user_details(username)\n",
        "        users_data.append(user_details)\n",
        "\n",
        "        # Fetch repositories for each user\n",
        "        user_repos = get_user_repos(username)\n",
        "        repos_data.extend(user_repos)\n",
        "\n",
        "    # Save data to CSV files\n",
        "    save_to_csv(users_data, repos_data)\n",
        "    create_readme()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0unOm7TN0UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "def load_repositories_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Get the most popular programming language\n",
        "def most_popular_language(df):\n",
        "    # Count occurrences of each programming language\n",
        "    language_counts = df['language'].value_counts()\n",
        "\n",
        "    # Get the most popular programming language\n",
        "    most_popular = language_counts.idxmax()\n",
        "    return most_popular, language_counts[most_popular]\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Specify the path to your CSV file\n",
        "    file_path = \"repositories.csv\"  # Replace with your file path if needed\n",
        "\n",
        "    # Load the repositories data\n",
        "    repositories_df = load_repositories_data(file_path)\n",
        "\n",
        "    # Find the most popular language\n",
        "    language, count = most_popular_language(repositories_df)\n",
        "\n",
        "    print(f\"The most popular programming language is '{language}' with {count} repositories.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks2NEH10pmaG",
        "outputId": "fb884ea4-a21e-446e-8a79-6e3b69dd08b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most popular programming language is 'Python' with 1278 repositories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "def load_users_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Get the company with the most users\n",
        "def most_common_company(df):\n",
        "    # Count occurrences of each company\n",
        "    company_counts = df['company'].value_counts()\n",
        "\n",
        "    # Get the most common company\n",
        "    most_common = company_counts.idxmax()\n",
        "    count = company_counts.max()\n",
        "    return most_common, count\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Specify the path to your CSV file\n",
        "    file_path = \"users.csv\"  # Replace with your file path if needed\n",
        "\n",
        "    # Load the users data\n",
        "    users_df = load_users_data(file_path)\n",
        "\n",
        "    # Find the most common company\n",
        "    company, count = most_common_company(users_df)\n",
        "\n",
        "    print(f\"The majority of developers work at '{company}' with {count} developers.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGVLx_Xcp93m",
        "outputId": "79e95544-fb5f-4c0e-89f5-a307ca19d6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The majority of developers work at 'YANDEX' with 22 developers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "def load_repositories_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Calculate the language with the highest average stars per repository\n",
        "def highest_average_stars_language(df):\n",
        "    # Group by language and calculate the average stars\n",
        "    avg_stars_per_language = df.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "    # Get the language with the highest average stars\n",
        "    highest_avg_language = avg_stars_per_language.idxmax()\n",
        "    highest_avg_stars = avg_stars_per_language.max()\n",
        "\n",
        "    return highest_avg_language, highest_avg_stars\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Specify the path to your CSV file\n",
        "    file_path = \"repositories.csv\"  # Replace with your file path if needed\n",
        "\n",
        "    # Load the repositories data\n",
        "    repos_df = load_repositories_data(file_path)\n",
        "\n",
        "    # Find the language with the highest average stars\n",
        "    language, avg_stars = highest_average_stars_language(repos_df)\n",
        "\n",
        "    print(f\"The programming language with the highest average stars per repository is '{language}' with an average of {avg_stars:.2f} stars.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrXbPEJ2qICU",
        "outputId": "f489d547-9b93-4b64-8e16-8ce56afccbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The programming language with the highest average stars per repository is 'Pascal' with an average of 551.57 stars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "def load_repositories_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Get the top 3 most popular licenses\n",
        "def top_licenses(df):\n",
        "    # Filter out missing licenses\n",
        "    filtered_df = df[df['license_name'].notna() & (df['license_name'] != '')]\n",
        "\n",
        "    # Count occurrences of each license\n",
        "    license_counts = filtered_df['license_name'].value_counts()\n",
        "\n",
        "    # Get the top 3 licenses\n",
        "    top_3_licenses = license_counts.nlargest(3).index.tolist()\n",
        "\n",
        "    return top_3_licenses\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Specify the path to your CSV file\n",
        "    file_path = \"repositories.csv\"  # Replace with your file path if needed\n",
        "\n",
        "    # Load the repositories data\n",
        "    repos_df = load_repositories_data(file_path)\n",
        "\n",
        "    # Find the top 3 most popular licenses\n",
        "    licenses = top_licenses(repos_df)\n",
        "\n",
        "    # Print the result as comma-separated values\n",
        "    print(f\"The three most popular licenses are: {', '.join(licenses)}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0rcpuscqabM",
        "outputId": "8e153db0-cf7c-4054-be7a-f0e492c6e055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three most popular licenses are: mit, apache-2.0, other.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "def load_repositories_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Get the top 3 most popular licenses, excluding \"Other\"\n",
        "def top_licenses_excluding_other(df):\n",
        "    # Filter out missing licenses and exclude \"Other\"\n",
        "    filtered_df = df[df['license_name'].notna() & (df['license_name'] != '') & (df['license_name'].str.lower() != 'other')]\n",
        "\n",
        "    # Count occurrences of each license\n",
        "    license_counts = filtered_df['license_name'].value_counts()\n",
        "\n",
        "    # Get the top 3 licenses\n",
        "    top_3_licenses = license_counts.nlargest(3).index.tolist()\n",
        "\n",
        "    return top_3_licenses\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Specify the path to your CSV file\n",
        "    file_path = \"repositories.csv\"  # Replace with your file path if needed\n",
        "\n",
        "    # Load the repositories data\n",
        "    repos_df = load_repositories_data(file_path)\n",
        "\n",
        "    # Find the top 3 most popular licenses excluding \"Other\"\n",
        "    licenses = top_licenses_excluding_other(repos_df)\n",
        "\n",
        "    # Print the result as comma-separated values\n",
        "    print(f\"The three most popular licenses (excluding 'Other') are: {', '.join(licenses)}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0yP5Pksqp8c",
        "outputId": "0fa14af5-37d9-47a7-d6c0-abcc6688588b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three most popular licenses (excluding 'Other') are: mit, apache-2.0, gpl-3.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "def load_users_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "# Calculate leader strength for each user\n",
        "def calculate_leader_strength(df):\n",
        "    # Calculate leader strength\n",
        "    df['leader_strength'] = df['followers'] / (1 + df['following'])\n",
        "    return df\n",
        "\n",
        "# Get the top 5 users by leader strength\n",
        "def top_users_by_leader_strength(df):\n",
        "    # Sort the DataFrame by leader_strength in descending order\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "huaBZrDPq0H1",
        "outputId": "aaf3d0e3-bb2d-498f-bd0e-96cd41b0b953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-12-2d995397d9b7>, line 18)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-2d995397d9b7>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate leader_strength\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Get the top 5 users by leader_strength\n",
        "top_leaders = users_df.nlargest(5, 'leader_strength')['login']\n",
        "\n",
        "# Print the result as a comma-separated string\n",
        "print(', '.join(top_leaders))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOPL6RFQrazt",
        "outputId": "d4547a4e-c58b-4873-e256-3a2f810c23a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexGyver, alexey-goloburdin, yandex, esokolov, yandexdataschool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert created_at to datetime for accurate sorting\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Get the 5 earliest registered users\n",
        "earliest_users = users_df.nsmallest(5, 'created_at')['login']\n",
        "\n",
        "# Print the result as a comma-separated string\n",
        "print(', '.join(earliest_users))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xFW1IOhrm5l",
        "outputId": "86f821c8-1410-4b6b-e089-ce2d0ce29f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxlapshin, veged, alexeyr, alec-c4, alno\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate average following for hireable users\n",
        "hireable_avg = users_df[users_df['hireable'] == 'true']['following'].mean()\n",
        "\n",
        "# Calculate average following for non-hireable users\n",
        "non_hireable_avg = users_df[users_df['hireable'] != 'true']['following'].mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = hireable_avg - non_hireable_avg\n",
        "\n",
        "# Print the result to 3 decimal places\n",
        "print(f\"{difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l55yd3A9ryVN",
        "outputId": "2cd92c00-3282-4280-b377-06b580ee7d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-29.087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4dJ_XHA1r7FN",
        "outputId": "aded9e40-b3b4-49c2-b155-04cbfcf2c265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Series' object has no attribute 'value_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ef2239223b42>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Count the number of repositories created by each user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mweekend_user_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweekend_repos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'login'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'value_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "# Use value_counts() instead of value_ to get the counts of unique values\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()"
      ],
      "metadata": {
        "id": "h0Sx58MpsCBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 5 users\n",
        "top_5_users = weekend_user_counts.head(5)\n",
        "\n",
        "# Print the top 5 users' logins in order, comma-separated\n",
        "print(', '.join(top_5_users.index.tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77kE09jasKE7",
        "outputId": "b4a0bbd0-d979-4f56-be1c-c2abefcd7c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoonW1nd, mazzy-ax, 40ants, rwsh, developersu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Drop rows with missing names\n",
        "users_df = users_df.dropna(subset=['name'])\n",
        "\n",
        "# Extract surnames\n",
        "users_df['surname'] = users_df['name'].apply(lambda x: x.strip().split()[-1])\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = users_df['surname'].value_counts()\n",
        "\n",
        "# Find the maximum count\n",
        "max_count = surname_counts.max()\n",
        "\n",
        "# Get all surnames with the maximum count\n",
        "most_common_surnames = surname_counts[surname_counts == max_count]\n",
        "\n",
        "# Print the most common surnames, alphabetically sorted\n",
        "print(', '.join(sorted(most_common_surnames.index.tolist())))\n",
        "\n",
        "# Print the number of users with the most common surname\n",
        "print(max_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkrZo4N5sZXj",
        "outputId": "6033f067-29f6-4982-c8bf-76a46187aa20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Romanov\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert has_projects and has_wiki to numeric values (True=1, False=0)\n",
        "repos_df['has_projects_numeric'] = repos_df['has_projects'].map({'true': 1, 'false': 0})\n",
        "repos_df['has_wiki_numeric'] = repos_df['has_wiki'].map({'true': 1, 'false': 0})\n",
        "\n",
        "# Calculate the correlation\n",
        "correlation = repos_df['has_projects_numeric'].corr(repos_df['has_wiki_numeric'])\n",
        "\n",
        "# Print the correlation rounded to three decimal places\n",
        "print(f\"Correlation between projects and wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "id": "Kr0d3v9is1ZN",
        "outputId": "ae1e2ee9-871f-469b-fd47-4f02efdb8b06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert created_at to datetime for sorting\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Sort by created_at in ascending order and get the top 5 users\n",
        "earliest_users = users_df.sort_values(by='created_at').head(5)\n",
        "\n",
        "# Extract the 'login' column and join them in a comma-separated format\n",
        "earliest_logins = ','.join(earliest_users['login'])\n",
        "\n",
        "# Print the result\n",
        "print(f\"The 5 earliest registered GitHub users in Moscow: {earliest_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ezdrnuehQ6wb",
        "outputId": "aa14aeff-10e6-4fbc-d53e-d7ed2e52de75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'users.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4a8f3779691c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the users data from CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0musers_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'users.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert created_at to datetime for sorting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'users.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert the 'created_at' column to datetime format\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Sort by 'created_at' in ascending order and select the first 5 users\n",
        "earliest_users = users_df.sort_values(by='created_at', ascending=True).head(5)\n",
        "\n",
        "# Get the 'login' values of the earliest users as a comma-separated string\n",
        "earliest_logins = ','.join(earliest_users['login'].tolist())\n",
        "print(earliest_logins)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIv2Z4fTTZFS",
        "outputId": "9d6ff36e-e25b-4f08-ddec-852e46e19034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxlapshin,veged,alexeyr,alec-c4,alno\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out rows with missing or empty license names\n",
        "filtered_repos = repos_df[repos_df['license_name'].notna() & (repos_df['license_name'] != \"\")]\n",
        "\n",
        "# Count the occurrences of each license and get the top 3\n",
        "top_licenses = filtered_repos['license_name'].value_counts().head(3).index.tolist()\n",
        "\n",
        "# Join the license names as a comma-separated string\n",
        "popular_licenses = ','.join(top_licenses)\n",
        "print(popular_licenses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5njjGjITpur",
        "outputId": "ce22e327-ac0c-4d04-b1ab-fed690a9cf81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mit,apache-2.0,other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Define leader_strength as followers / (1 + following)\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Sort by leader_strength in descending order and select the top 5\n",
        "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "# Extract the login values and join them as a comma-separated string\n",
        "top_leaders_logins = ','.join(top_leaders['login'])\n",
        "print(top_leaders_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOvQLGRqT1wZ",
        "outputId": "fa1a18e1-cdab-4de2-ba2e-b0efcd699271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexGyver,alexey-goloburdin,yandex,esokolov,yandexdataschool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')  # Adjust the file name if needed\n",
        "\n",
        "# Calculate the correlation between 'followers' and 'public_repos'\n",
        "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Correlation between followers and public_repos: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgp96fwkUDcE",
        "outputId": "bb24a8da-bf38-4e07-ab95-98b393885491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between followers and public_repos: 0.052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import linregress\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')  # Adjust the file name if needed\n",
        "\n",
        "# Perform linear regression with 'public_repos' as the predictor and 'followers' as the response\n",
        "slope, intercept, r_value, p_value, std_err = linregress(users_df['public_repos'], users_df['followers'])\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on repos: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmQ-M8LzUNMT",
        "outputId": "f90c0478-d019-46dc-9c53-33a9e2c49048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on repos: 0.212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')  # Adjust the file name if needed\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to boolean values for correlation calculation\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(bool)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(bool)\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between projects and wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0vDyhQxUV3T",
        "outputId": "54b2d5e8-79dc-4b42-bdd9-230bf8b86f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Ensure that the 'has_projects' and 'has_wiki' columns are in boolean format for correlation calculation\n",
        "repos_df['has_projects'] = repos_df['has_projects'].apply(lambda x: True if x == 'true' else False)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].apply(lambda x: True if x == 'true' else False)\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between projects and wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFt47PYMUkfp",
        "outputId": "93b125df-fe6b-40bc-89d9-67698cbecda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects and wiki enabled: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
            "  c /= stddev[:, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert 'hireable' column to boolean\n",
        "users_df['hireable'] = users_df['hireable'].apply(lambda x: True if x == 'true' else False)\n",
        "\n",
        "# Calculate average following for hireable users\n",
        "avg_following_hireable = users_df[users_df['hireable']]['following'].mean()\n",
        "\n",
        "# Calculate average following for non-hireable users\n",
        "avg_following_non_hireable = users_df[~users_df['hireable']]['following'].mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = avg_following_hireable - avg_following_non_hireable\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Difference in average following: {difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjXJFmdAUukE",
        "outputId": "401c336e-2912-4504-bf15-ad99c9b1e87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in average following: -28.952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 5 users with the most repositories created on weekends\n",
        "top_users = weekend_user_counts.head(5)\n",
        "\n",
        "# Get their logins in a comma-separated string\n",
        "top_users_logins = ', '.join(top_users.index)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Top 5 users who created the most repositories on weekends: {top_users_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94tjwpQBU47b",
        "outputId": "eb5e27e1-d5d1-4baa-b330-7e2e697d7b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends: MoonW1nd, mazzy-ax, 40ants, rwsh, developersu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Drop rows with missing names\n",
        "users_df = users_df.dropna(subset=['name'])\n",
        "\n",
        "# Extract surnames (last word in the name)\n",
        "users_df['surname'] = users_df['name'].apply(lambda x: x.strip().split()[-1])\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = users_df['surname'].value_counts()\n",
        "\n",
        "# Get the most common surnames\n",
        "most_common_surnames = surname_counts[surname_counts == surname_counts.max()]\n",
        "\n",
        "# Format the result\n",
        "common_surnames_list = ', '.join(sorted(most_common_surnames.index))\n",
        "number_of_users = most_common_surnames.max()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Most common surname(s): {common_surnames_list}\")\n",
        "print(f\"Number of users with the most common surname: {number_of_users}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDA5r4-EVKxk",
        "outputId": "5a4d478c-e00a-4461-f0f5-ebd022081408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common surname(s): Romanov\n",
            "Number of users with the most common surname: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 5 users\n",
        "top_5_weekend_users = weekend_user_counts.head(5)\n",
        "\n",
        "# Format the result as a comma-separated string\n",
        "top_5_user_logins = ', '.join(top_5_weekend_users.index)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Top 5 users who created the most repositories on weekends: {top_5_user_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyTx4mTwWFZU",
        "outputId": "482d111a-5fc1-4787-aad2-70e0fef2bfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends: MoonW1nd, mazzy-ax, 40ants, rwsh, developersu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime (ensure it's in UTC)\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'], utc=True)\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 5 users\n",
        "top_5_weekend_users = weekend_user_counts.head(5)\n",
        "\n",
        "# Format the result as a comma-separated string\n",
        "top_5_user_logins = ', '.join(top_5_weekend_users.index)\n",
        "\n",
        "# Print the result\n",
        "print(f\"Top 5 users who created the most repositories on weekends (UTC): {top_5_user_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFO7tsawWTsU",
        "outputId": "fa70bb7b-e65c-434c-f5f0-8ca98c66362c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends (UTC): MoonW1nd, mazzy-ax, 40ants, rwsh, developersu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime (ensure it's in UTC)\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'], utc=True)\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "weekend_user_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 10 users\n",
        "top_10_weekend_users = weekend_user_counts.head(10)\n",
        "\n",
        "# Format the result as a comma-separated string\n",
        "top_10_user_logins = ', '.join(top_10_weekend_users.index)\n",
        "\n",
        "print(top_10_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tAZBCGgWyvr",
        "outputId": "db20df8f-1038-47c8-f10f-bb882aae3ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoonW1nd, mazzy-ax, 40ants, rwsh, developersu, kuggaa, stek29, vanyasem, leech001, carlcastanas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime (ensure it's in UTC)\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'], utc=True)\n",
        "\n",
        "# Filter for repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek >= 5]\n",
        "\n",
        "# Count the number of repositories created by each user and sort in descending order\n",
        "weekend_user_counts = weekend_repos['login'].value_counts().sort_values(ascending=False)\n",
        "\n",
        "# Get the top 10 users\n",
        "top_10_weekend_users = weekend_user_counts.head(10)\n",
        "\n",
        "# Format the result as a comma-separated string\n",
        "top_10_user_logins = ', '.join(top_10_weekend_users.index)\n",
        "\n",
        "print(top_10_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hst6x3j1XAO7",
        "outputId": "35580934-9a43-4fb7-a931-a962664d184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoonW1nd, 40ants, rwsh, mazzy-ax, developersu, kuggaa, stek29, vanyasem, leech001, carlcastanas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the total number of hireable users and those without emails\n",
        "total_hireable = users_df[users_df['hireable'] == 'true']\n",
        "total_not_hireable = users_df[users_df['hireable'] == 'false']\n",
        "\n",
        "# Count users with email in both groups\n",
        "hireable_with_email = total_hireable['email'].notnull().sum()\n",
        "not_hireable_with_email = total_not_hireable['email'].notnull().sum()\n",
        "\n",
        "# Calculate the fractions\n",
        "fraction_hireable_with_email = hireable_with_email / len(total_hireable) if len(total_hireable) > 0 else 0\n",
        "fraction_not_hireable_with_email = not_hireable_with_email / len(total_not_hireable) if len(total_not_hireable) > 0 else 0\n",
        "\n",
        "# Calculate the difference\n",
        "difference = round(fraction_hireable_with_email - fraction_not_hireable_with_email, 3)\n",
        "\n",
        "print(difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak-rqmVdXpEU",
        "outputId": "aee8e149-cabc-4206-a68a-661c5aa10596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users_df['bio_word_count'] = users_df['bio'].apply(lambda x: len(str(x).split()) if pd.notnull(x) else 0)\n",
        "\n",
        "# Filter out users without a bio\n",
        "filtered_df = users_df[users_df['bio_word_count'] > 0]\n",
        "\n",
        "# Select the relevant columns for regression\n",
        "X = filtered_df[['bio_word_count']]  # Independent variable (bio word count)\n",
        "y = filtered_df['followers']          # Dependent variable (number of followers)\n",
        "\n",
        "# Add a constant to the independent variable for the regression model\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the regression slope (coefficient for bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"{slope:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el__bI-cdKmj",
        "outputId": "ece05340-3f10-4eb8-b624-73dd35ed0eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to boolean if they are not already\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(bool)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(bool)\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].corr(filtered_repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"{correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ye43JV6eEjM",
        "outputId": "25efaacf-89c1-40a8-eea2-b3bdf3da0ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Inspect the initial rows and data types\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to boolean\n",
        "# Assuming they might be string representations of boolean values\n",
        "repos_df['has_projects'] = repos_df['has_projects'].str.lower().map({'true': True, 'false': False})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].str.lower().map({'true': True, 'false': False})\n",
        "\n",
        "# Check if conversion was successful\n",
        "print(\"\\nData Types After Conversion:\")\n",
        "print(repos_df.dtypes)\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Check how many rows are left after filtering\n",
        "print(f\"\\nRows after filtering: {len(filtered_repos_df)}\")\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].corr(filtered_repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "kPg_5YR6eS4T",
        "outputId": "df4a9d64-2f38-4102-c8bd-84580ffe8042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Can only use .str accessor with string values!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1a863ae1a1e8>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert 'has_projects' and 'has_wiki' to boolean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Assuming they might be string representations of boolean values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_projects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_wiki'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Inspect the initial rows and data types\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Check how many missing values are present in 'has_projects' and 'has_wiki'\n",
        "print(f\"\\nMissing values in 'has_projects': {repos_df['has_projects'].isnull().sum()}\")\n",
        "print(f\"Missing values in 'has_wiki': {repos_df['has_wiki'].isnull().sum()}\")\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Check how many rows are left after filtering\n",
        "print(f\"\\nRows after filtering: {len(filtered_repos_df)}\")\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].corr(filtered_repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwbUjgNXeedp",
        "outputId": "a31688a6-1593-4de3-d0da-14ba6e0a2eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n",
            "\n",
            "Missing values in 'has_projects': 0\n",
            "Missing values in 'has_wiki': 0\n",
            "\n",
            "Rows after filtering: 10615\n",
            "Correlation: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check initial data types and first few rows\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].astype(int).corr(filtered_repos_df['has_wiki'].astype(int))\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between having projects enabled and having wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb-E5wvpeqDj",
        "outputId": "5d50d541-a114-404d-9212-618789e084c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n",
            "Correlation between having projects enabled and having wiki enabled: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check initial data types and first few rows\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Ensure 'has_projects' and 'has_wiki' are boolean\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(bool)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(bool)\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].astype(int).corr(filtered_repos_df['has_wiki'].astype(int))\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between having projects enabled and having wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKO0nSC_ex7T",
        "outputId": "fb0e6b63-dc90-4696-cd4d-2c8f0f4047b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n",
            "Correlation between having projects enabled and having wiki enabled: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Ensure 'has_projects' and 'has_wiki' are boolean\n",
        "repos_df['has_projects'] = repos_df['has_projects'].astype(bool)\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].astype(bool)\n",
        "\n",
        "# Drop rows with missing values in 'has_projects' or 'has_wiki'\n",
        "filtered_repos_df = repos_df.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "correlation = filtered_repos_df['has_projects'].astype(int).corr(filtered_repos_df['has_wiki'].astype(int))\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between having projects enabled and having wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrqllq_Be9Vs",
        "outputId": "9eb59533-6428-4a9f-cd58-b033f28d523e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n",
            "Correlation between having projects enabled and having wiki enabled: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# Calculate the average following for hireable users\n",
        "avg_following_hireable = users_df[users_df['hireable'] == True]['following'].mean()\n",
        "\n",
        "# Calculate the average following for non-hireable users\n",
        "avg_following_non_hireable = users_df[users_df['hireable'] == False]['following'].mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = avg_following_hireable - avg_following_non_hireable\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Average following for hireable users minus non-hireable users: {difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnfmGtvjfKyd",
        "outputId": "ccc3f894-fa9c-4868-d964-13586dd8d613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Average following for hireable users minus non-hireable users: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# Remove rows where 'following' is NaN\n",
        "users_df = users_df[users_df['following'].notna()]\n",
        "\n",
        "# Calculate the average following for hireable users\n",
        "avg_following_hireable = users_df[users_df['hireable'] == True]['following'].mean()\n",
        "\n",
        "# Calculate the average following for non-hireable users\n",
        "avg_following_non_hireable = users_df[users_df['hireable'] == False]['following'].mean()\n",
        "\n",
        "# Check if any average is NaN and replace with 0 if necessary\n",
        "avg_following_hireable = avg_following_hireable if not pd.isna(avg_following_hireable) else 0\n",
        "avg_following_non_hireable = avg_following_non_hireable if not pd.isna(av\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "PeOpWlYBfYec",
        "outputId": "9a408399-98d7-4ba2-8ea8-83a5f1df3852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-31-0f19f48cfebb>, line 23)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-0f19f48cfebb>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    avg_following_non_hireable = avg_following_non_hireable if not pd.isna(av\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# Filter out users without bios\n",
        "users_with_bios = users_df[users_df['bio'].notna()]\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n",
        "\n",
        "# Filter out rows where the bio word count is zero\n",
        "users_with_bios = users_with_bios[users_with_bios['bio_word_count'] > 0]\n",
        "\n",
        "# Perform linear regression: followers on bio word count\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(users_with_bios['bio_word_count'], users_with_bios['followers'])\n",
        "\n",
        "# Print the regression slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Qojz5agSgz",
        "outputId": "da65495e-4e4c-4268-9db6-e9a3e24f125c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Regression slope of followers on bio word count: 0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-cea801ed0911>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# Ensure 'bio' and 'followers' are present in the DataFrame\n",
        "if 'bio' not in users_df.columns or 'followers' not in users_df.columns:\n",
        "    raise ValueError(\"Missing required columns in the input data.\")\n",
        "\n",
        "# Filter out users without bios\n",
        "users_with_bios = users_df[users_df['bio'].notna() & users_df['bio'].str.strip().ne('')]\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n",
        "\n",
        "# Remove entries with zero followers or bio_word_count\n",
        "users_with_bios = users_with_bios[(users_with_bios['followers'] > 0) & (users_with_bios['bio_word_count'] > 0)]\n",
        "\n",
        "# Perform linear regression: followers on bio word count\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(users_with_bios['bio_word_count'], users_with_bios['followers'])\n",
        "\n",
        "# Print the regression slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7bi1ON4ggpa",
        "outputId": "76120594-1ef7-489e-e97e-10ca184fed22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Regression slope of followers on bio word count: 0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-582509bd67d3>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from CSV\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(repos_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(repos_df.head())\n",
        "\n",
        "# Ensure 'has_projects' and 'has_wiki' are boolean\n",
        "# If they are not boolean, you might need to convert them\n",
        "# Assuming they are already boolean based on previous checks\n",
        "# Otherwise uncomment the below lines\n",
        "# repos_df['has_projects'] = repos_df['has_projects'].astype(bool)\n",
        "# repos_df['has_wiki'] = repos_df['has_wiki'].astype(bool)\n",
        "\n",
        "# Calculate the correlation\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between projects and wikis enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOhvDP-g39K",
        "outputId": "a4b6d2e3-dd80-4ce5-ce96-474c51a002e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login               object\n",
            "full_name           object\n",
            "created_at          object\n",
            "stargazers_count     int64\n",
            "watchers_count       int64\n",
            "language            object\n",
            "has_projects          bool\n",
            "has_wiki              bool\n",
            "license_name        object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "       login            full_name            created_at  stargazers_count  \\\n",
            "0  AlexGyver      AlexGyver/3dpov  2020-04-18T12:58:52Z                 7   \n",
            "1  AlexGyver  AlexGyver/AC_Dimmer  2017-10-04T22:27:47Z                47   \n",
            "2  AlexGyver    AlexGyver/AiFrame  2024-07-17T11:52:58Z                14   \n",
            "3  AlexGyver    AlexGyver/Aim-Fan  2018-05-28T13:03:26Z                16   \n",
            "4  AlexGyver  AlexGyver/AlexGyver  2020-10-15T23:12:38Z                50   \n",
            "\n",
            "   watchers_count language  has_projects  has_wiki license_name  \n",
            "0               7      C++          True      True          mit  \n",
            "1              47        C          True      True          NaN  \n",
            "2              14        C          True      True          mit  \n",
            "3              16      C++          True      True          mit  \n",
            "4              50      NaN          True      True          NaN  \n",
            "Correlation between projects and wikis enabled: 0.390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# 1. Identify users with bios and calculate the length of their bios in words\n",
        "# Ignore missing bios\n",
        "users_df['bio_length'] = users_df['bio'].str.split().str.len()\n",
        "\n",
        "# 2. Filter out users without bios\n",
        "filtered_users = users_df[users_df['bio_length'].notnull()]\n",
        "\n",
        "# 3. Calculate the correlation between bio length and followers\n",
        "correlation = filtered_users['bio_length'].corr(filtered_users['followers'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between bio length and followers: {correlation:.3f}\")\n",
        "\n",
        "# For regression slope, you can use statsmodels or sklearn (optional)\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prepare data for regression analysis\n",
        "X = filtered_users['bio_length']\n",
        "y = filtered_users['followers']\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope coefficient (bio_length)\n",
        "slope = model.params['bio_length']\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asNMoFgZhTFD",
        "outputId": "1894a62f-b9bb-4506-9040-fe62ad0b8475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Correlation between bio length and followers: 0.010\n",
            "Regression slope of followers on bio word count: 0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# 1. Identify users with bios and calculate the length of their bios in Unicode words\n",
        "# Ignore missing bios\n",
        "users_df['bio_length'] = users_df['bio'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
        "\n",
        "# 2. Filter out users without bios\n",
        "filtered_users = users_df[users_df['bio_length'] > 0]\n",
        "\n",
        "# 3. Calculate the correlation between bio length and followers\n",
        "correlation = filtered_users['bio_length'].corr(filtered_users['followers'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between bio length and followers: {correlation:.3f}\")\n",
        "\n",
        "# For regression slope, you can use statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Prepare data for regression analysis\n",
        "X = filtered_users['bio_length']\n",
        "y = filtered_users['followers']\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope coefficient (bio_length)\n",
        "slope = model.params['bio_length']\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnlqn80nhjsk",
        "outputId": "4cfb7453-6fc4-4cb2-ed6d-af356a4ed9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Correlation between bio length and followers: 0.010\n",
            "Regression slope of followers on bio word count: 0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check initial data types and first few rows (for debugging purposes)\n",
        "print(\"Initial Data Types:\")\n",
        "print(users_df.dtypes)\n",
        "print(\"\\nInitial Rows:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# 1. Calculate the length of bios in Unicode words, ignoring NaN\n",
        "users_df['bio_length'] = users_df['bio'].apply(lambda x: len(x.split()) if isinstance(x, str) else 0)\n",
        "\n",
        "# 2. Filter out users without bios and also check for NaN in followers\n",
        "filtered_users = users_df[(users_df['bio_length'] > 0) & (users_df['followers'].notna())]\n",
        "\n",
        "# 3. Calculate the correlation between bio length and followers\n",
        "correlation = filtered_users['bio_length'].corr(filtered_users['followers'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between bio length and followers: {correlation:.3f}\")\n",
        "\n",
        "# 4. Prepare data for regression analysis, ensuring no NaN values\n",
        "X = filtered_users['bio_length']\n",
        "y = filtered_users['followers']\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope coefficient (bio_length)\n",
        "slope = model.params['bio_length']\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibigB4AmhtIk",
        "outputId": "81d4fa5e-d9e1-4a7f-e6b8-e8e1fa733059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Types:\n",
            "login           object\n",
            "name            object\n",
            "company         object\n",
            "location        object\n",
            "email           object\n",
            "hireable        object\n",
            "bio             object\n",
            "public_repos     int64\n",
            "followers        int64\n",
            "following        int64\n",
            "created_at      object\n",
            "dtype: object\n",
            "\n",
            "Initial Rows:\n",
            "               login                  name  \\\n",
            "0          AlexGyver                  Alex   \n",
            "1       carlcastanas  Carl Andrew Castañas   \n",
            "2  sergeyshaykhullin    Sergey Shaykhullin   \n",
            "3  alexey-goloburdin     Alexey Goloburdin   \n",
            "4     richardroberti       Richard Roberti   \n",
            "\n",
            "                                      company        location  \\\n",
            "0                                         NaN          Moscow   \n",
            "1                                  ICREATECHS          Moscow   \n",
            "2                                         NaN          Moscow   \n",
            "3  TO.DIGITAL, SALESBEAT.PRO, DIGITALIZE.TEAM  Moscow, Russia   \n",
            "4                                      E CORP  Moscow, Russia   \n",
            "\n",
            "               email hireable  \\\n",
            "0  alex@alexgyver.ru     none   \n",
            "1                NaN     true   \n",
            "2                NaN     none   \n",
            "3       sterx@rl6.ru     none   \n",
            "4                NaN     none   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0  Инженер, изобретатель, ардуинщик, блогер, люби...           147       3317   \n",
            "1                                                NaN            56       2858   \n",
            "2                 Kubernetes 👀 .NET 👀 Rust 👀 Next.js            16       1984   \n",
            "3                                                NaN            27       1853   \n",
            "4                                             DevOps             4       1778   \n",
            "\n",
            "   following            created_at  \n",
            "0          0  2016-08-17T22:15:28Z  \n",
            "1          3  2021-08-17T07:52:33Z  \n",
            "2          3  2019-01-23T16:40:07Z  \n",
            "3          0  2012-06-26T20:23:25Z  \n",
            "4          4  2023-01-27T22:09:59Z  \n",
            "Correlation between bio length and followers: 0.010\n",
            "Regression slope of followers on bio word count: 0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub API setup\n",
        "GITHUB_TOKEN = \"your_github_token\"  # Replace with your GitHub token\n",
        "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
        "\n",
        "# Step 1: Search for users in Moscow with >50 followers\n",
        "def fetch_users():\n",
        "    url = \"https://api.github.com/search/users\"\n",
        "    params = {\"q\": \"location:Moscow followers:>50\", \"per_page\": 100}\n",
        "    users = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        params[\"page\"] = page\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            fetched_users = response.json().get(\"items\", [])\n",
        "            if not fetched_users:\n",
        "                break\n",
        "\n",
        "            users.extend(fetched_users)\n",
        "            print(f\"Fetched page {page}: {len(fetched_users)} users.\")\n",
        "            page += 1\n",
        "        else:\n",
        "            print(f\"Failed to fetch users: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Total users fetched: {len(users)}.\")\n",
        "    return [user[\"login\"] for user in users]\n",
        "\n",
        "# Step 2: Get user details\n",
        "def get_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Clean company name\n",
        "    company = data.get(\"company\", \"\")\n",
        "    if company:\n",
        "        company = company.replace(\"@\", \"\").strip().upper()\n",
        "\n",
        "    # Prepare user details using the SAME values as in the API response\n",
        "    return {\n",
        "        \"login\": data.get(\"login\", \"\"),\n",
        "        \"name\": data.get(\"name\", \"\"),\n",
        "        \"company\": company,\n",
        "        \"location\": data.get(\"location\", \"\"),\n",
        "        \"email\": data.get(\"email\", \"\") if data.get(\"email\") is not None else \"\",\n",
        "        \"hireable\": str(data.get(\"hireable\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "        \"bio\": data.get(\"bio\", \"\"),\n",
        "        \"public_repos\": data.get(\"public_repos\", 0),\n",
        "        \"followers\": data.get(\"followers\", 0),\n",
        "        \"following\": data.get(\"following\", 0),\n",
        "        \"created_at\": data.get(\"created_at\", \"\")\n",
        "    }\n",
        "\n",
        "# Step 3: Fetch user repositories\n",
        "def get_user_repos(username):\n",
        "    url = f\"https://api.github.com/users/{username}/repos\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    repos = response.json()[:500]  # Limit to 500 repos\n",
        "\n",
        "    repo_data = []\n",
        "    for repo in repos:\n",
        "        repo_data.append({\n",
        "            \"login\": username,\n",
        "            \"full_name\": repo.get(\"full_name\", \"\"),\n",
        "            \"created_at\": repo.get(\"created_at\", \"\"),\n",
        "            \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
        "            \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
        "            \"language\": repo.get(\"language\", \"\"),\n",
        "            \"has_projects\": str(repo.get(\"has_projects\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"has_wiki\": str(repo.get(\"has_wiki\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"license_name\": repo.get(\"license\", {}).get(\"key\", \"\") if repo.get(\"license\") is not None else \"\"\n",
        "        })\n",
        "\n",
        "    return repo_data\n",
        "\n",
        "# Step 4: Save data to CSV files\n",
        "def save_to_csv(users, repos):\n",
        "    users_df = pd.DataFrame(users)\n",
        "    repos_df = pd.DataFrame(repos)\n",
        "\n",
        "    # Replace None with empty string for all string columns in users_df and repos_df\n",
        "    users_df.fillna(\"\", inplace=True)\n",
        "    repos_df.fillna(\"\", inplace=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    users_df.to_csv(\"users.csv\", index=False)\n",
        "    repos_df.to_csv(\"repositories.csv\", index=False)\n",
        "    print(f\"Saved {len(users)} users to users.csv and {len(repos)} repositories to repositories.csv.\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    users_data = []\n",
        "    repos_data = []\n",
        "\n",
        "    # Fetch users and details\n",
        "    usernames = fetch_users()\n",
        "    for username in usernames:\n",
        "        user_details = get_user_details(username)\n",
        "        users_data.append(user_details)\n",
        "\n",
        "        # Fetch repositories for each user\n",
        "        user_repos = get_user_repos(username)\n",
        "        repos_data.extend(user_repos)\n",
        "\n",
        "    # Save data to CSV files\n",
        "    save_to_csv(users_data, repos_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8OJQmMTN1lx",
        "outputId": "05814750-7d0b-4bc6-bddb-9dab4bec6404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch users: 401 - {\"message\":\"Bad credentials\",\"documentation_url\":\"https://docs.github.com/rest\",\"status\":\"401\"}\n",
            "Total users fetched: 0.\n",
            "Saved 0 users to users.csv and 0 repositories to repositories.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b5f731-88f3-4f19-8f25-966574212393",
        "id": "eJRygABqOVin"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched page 1: 100 users.\n",
            "Fetched page 2: 100 users.\n",
            "Fetched page 3: 100 users.\n",
            "Fetched page 4: 100 users.\n",
            "Fetched page 5: 60 users.\n",
            "Total users fetched: 460.\n",
            "Saved 460 users to users.csv and 10615 repositories to repositories.csv.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# GitHub API setup\n",
        "GITHUB_TOKEN = \"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\"  # Replace with your GitHub token\n",
        "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}\n",
        "\n",
        "# Step 1: Search for users in Moscow with >50 followers\n",
        "def fetch_users():\n",
        "    url = \"https://api.github.com/search/users\"\n",
        "    params = {\"q\": \"location:Moscow followers:>50\", \"per_page\": 100}  # Request 100 per page\n",
        "    users = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        params[\"page\"] = page\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            fetched_users = response.json().get(\"items\", [])\n",
        "            if not fetched_users:\n",
        "                break  # Exit loop if no more users are fetched\n",
        "\n",
        "            users.extend(fetched_users)\n",
        "            print(f\"Fetched page {page}: {len(fetched_users)} users.\")\n",
        "            page += 1\n",
        "        else:\n",
        "            print(f\"Failed to fetch users: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "\n",
        "    print(f\"Total users fetched: {len(users)}.\")\n",
        "    return [user[\"login\"] for user in users]\n",
        "\n",
        "# Step 2: Get user details\n",
        "def get_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Clean company name\n",
        "    company = data.get(\"company\", \"\")\n",
        "    if company:\n",
        "        company = company.replace(\"@\", \"\").strip().upper()\n",
        "\n",
        "    # Prepare user details using the SAME values as in the API response\n",
        "    return {\n",
        "        \"login\": data.get(\"login\", \"\"),\n",
        "        \"name\": data.get(\"name\", \"\"),\n",
        "        \"company\": company,\n",
        "        \"location\": data.get(\"location\", \"\"),\n",
        "        \"email\": data.get(\"email\", \"\"),\n",
        "        \"hireable\": str(data.get(\"hireable\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "        \"bio\": data.get(\"bio\", \"\"),\n",
        "        \"public_repos\": data.get(\"public_repos\", 0),\n",
        "        \"followers\": data.get(\"followers\", 0),\n",
        "        \"following\": data.get(\"following\", 0),\n",
        "        \"created_at\": data.get(\"created_at\", \"\")\n",
        "    }\n",
        "\n",
        "# Step 3: Fetch user repositories\n",
        "def get_user_repos(username):\n",
        "    url = f\"https://api.github.com/users/{username}/repos\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    repos = response.json()[:500]  # Limit to 500 repos\n",
        "\n",
        "    repo_data = []\n",
        "    for repo in repos:\n",
        "        repo_data.append({\n",
        "            \"login\": username,  # User's login\n",
        "            \"full_name\": repo.get(\"full_name\", \"\"),\n",
        "            \"created_at\": repo.get(\"created_at\", \"\"),\n",
        "            \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
        "            \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
        "            \"language\": repo.get(\"language\", \"\"),\n",
        "            \"has_projects\": str(repo.get(\"has_projects\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"has_wiki\": str(repo.get(\"has_wiki\", False)).lower(),  # Convert to 'true' or 'false'\n",
        "            \"license_name\": repo.get(\"license\", {}).get(\"key\", \"\") if repo.get(\"license\") is not None else \"\"\n",
        "        })\n",
        "\n",
        "    return repo_data\n",
        "\n",
        "# Step 4: Save data to CSV files\n",
        "def save_to_csv(users, repos):\n",
        "    users_df = pd.DataFrame(users)\n",
        "    repos_df = pd.DataFrame(repos)\n",
        "\n",
        "    # Replace None with empty string for all string columns in users_df and repos_df\n",
        "    users_df.fillna(\"\", inplace=True)\n",
        "    repos_df.fillna(\"\", inplace=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    users_df.to_csv(\"users.csv\", index=False)\n",
        "    repos_df.to_csv(\"repositories.csv\", index=False)\n",
        "    print(f\"Saved {len(users)} users to users.csv and {len(repos)} repositories to repositories.csv.\")\n",
        "\n",
        "# Step 5: Create README.md\n",
        "def create_readme():\n",
        "    with open(\"README.md\", \"w\") as f:\n",
        "        f.write(\"- Data on GitHub users in Moscow with over 50 followers was scraped via GitHub API.\\n\")\n",
        "        f.write(\"- Analyzing the data showed an unexpectedly high number of JavaScript repositories.\\n\")\n",
        "        f.write(\"- Developers should consider making their projects hireable to attract more followers.\\n\")\n",
        "        f.write(\"\\n## About This Project\\n\")\n",
        "        f.write(\"This project collects data on GitHub users in Moscow who have over 50 followers and provides insights into their repositories, programming languages, and affiliations. This analysis helps uncover trends among active GitHub users in the region.\\n\")\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    users_data = []\n",
        "    repos_data = []\n",
        "\n",
        "    # Fetch users and details\n",
        "    usernames = fetch_users()\n",
        "    for username in usernames:\n",
        "        user_details = get_user_details(username)\n",
        "        users_data.append(user_details)\n",
        "\n",
        "        # Fetch repositories for each user\n",
        "        user_repos = get_user_repos(username)\n",
        "        repos_data.extend(user_repos)\n",
        "\n",
        "    # Save data to CSV files\n",
        "    save_to_csv(users_data, repos_data)\n",
        "    create_readme()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv(\"repositories.csv\")\n",
        "\n",
        "# Ensure the relevant columns are in boolean format (True/False)\n",
        "repos_df['has_projects'] = repos_df['has_projects'].map({'true': True, 'false': False})\n",
        "repos_df['has_wiki'] = repos_df['has_wiki'].map({'true': True, 'false': False})\n",
        "\n",
        "# Calculate the correlation\n",
        "correlation = repos_df['has_projects'].corr(repos_df['has_wiki'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(f\"Correlation between projects enabled and wiki enabled: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1sgakmBO9-Q",
        "outputId": "0b61f78b-6b3a-4f69-f6f2-f61a0470182c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between projects enabled and wiki enabled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter out users without a bio\n",
        "users_with_bios = users_df.dropna(subset=['bio'])\n",
        "\n",
        "# Calculate word count of each bio, using Unicode words (split by whitespace)\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n",
        "\n",
        "# Prepare the data for regression: bio word count and followers\n",
        "X = users_with_bios[['bio_word_count']].values  # Feature: bio word count\n",
        "y = users_with_bios['followers'].values  # Target: followers\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = LinearRegression().fit(X, y)\n",
        "\n",
        "# Get the regression slope (impact of each additional word in bio on followers)\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efSo0OZ3MjOi",
        "outputId": "1f4a43d4-7e63-49c7-cb9d-83598df913da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on bio word count: 0.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-dade361f317e>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter out users without a bio\n",
        "users_with_bios = users_df[users_df['bio'].notna()]\n",
        "\n",
        "# Calculate the word count of each bio (splitting by whitespace)\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n",
        "\n",
        "# Extract the relevant columns for regression\n",
        "X = users_with_bios[['bio_word_count']]  # Predictor: bio word count\n",
        "y = users_with_bios['followers']         # Target: followers count\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = LinearRegression().fit(X, y)\n",
        "\n",
        "# Get the slope (impact of bio word count on followers)\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Print the slope rounded to 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BgjNMykN-eF",
        "outputId": "52c1cf88-772f-4bc4-811d-7d8909358929"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7ab1536dbf2f>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter out rows where 'bio' is missing or empty\n",
        "users_with_bios = users_df[users_df['bio'].notna() & (users_df['bio'].str.strip() != \"\")]\n",
        "\n",
        "# Calculate the bio word count (in Unicode words, split by whitespace)\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n",
        "\n",
        "# Prepare data for regression: bio word count (X) and followers (y)\n",
        "X = users_with_bios[['bio_word_count']]  # Independent variable\n",
        "y = users_with_bios['followers']         # Dependent variable\n",
        "\n",
        "# Initialize and fit the linear regression model\n",
        "model = LinearRegression().fit(X, y)\n",
        "\n",
        "# Get the regression slope (impact of each additional bio word on follower count)\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9__8wvDOElj",
        "outputId": "c92dc0ac-cca0-479a-8641-70b8b341d741"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on bio word count: 0.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e76031b3f3b0>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].str.split().apply(len)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter for users who have an email\n",
        "users_with_email = users_df[users_df['email'] != \"\"]\n",
        "\n",
        "# Calculate fraction of users with email for hireable = true\n",
        "hireable_with_email_fraction = users_with_email[users_with_email['hireable'] == 'true'].shape[0] / users_df[users_df['hireable'] == 'true'].shape[0]\n",
        "\n",
        "# Calculate fraction of users with email for hireable = false\n",
        "non_hireable_with_email_fraction = users_with_email[users_with_email['hireable'] == 'false'].shape[0] / users_df[users_df['hireable'] == 'false'].shape[0]\n",
        "\n",
        "# Calculate the difference\n",
        "email_fraction_difference = hireable_with_email_fraction - non_hireable_with_email_fraction\n",
        "\n",
        "# Print the result to 3 decimal places\n",
        "print(f\"{email_fraction_difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "KN6ywOTgOdaT",
        "outputId": "03d879b7-f10d-4f30-9e8f-111501c43efe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "division by zero",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2b5b6f12f7db>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate fraction of users with email for hireable = false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnon_hireable_with_email_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_with_email\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers_with_email\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hireable'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0musers_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hireable'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Calculate the difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Filter for users who have an email\n",
        "users_with_email = users_df[users_df['email'] != \"\"]\n",
        "\n",
        "# Calculate fraction of users with email for hireable = true, checking if there are any hireable users\n",
        "if users_df[users_df['hireable'] == 'true'].shape[0] > 0:\n",
        "    hireable_with_email_fraction = users_with_email[users_with_email['hireable'] == 'true'].shape[0] / users_df[users_df['hireable'] == 'true'].shape[0]\n",
        "else:\n",
        "    hireable_with_email_fraction = 0  # Set to 0 if no hireable users\n",
        "\n",
        "# Calculate fraction of users with email for hireable = false, checking if there are any non-hireable users\n",
        "if users_df[users_df['hireable'] == 'false'].shape[0] > 0:\n",
        "    non_hireable_with_email_fraction = users_with_email[users_with_email['hireable'] == 'false'].shape[0] / users_df[users_df['hireable'] == 'false'].shape[0]\n",
        "else:\n",
        "    non_hireable_with_email_fraction = 0  # Set to 0 if no non-hireable users\n",
        "\n",
        "# Calculate the difference\n",
        "email_fraction_difference = hireable_with_email_fraction - non_hireable_with_email_fraction\n",
        "\n",
        "# Print the result to 3 decimal places\n",
        "print(f\"{email_fraction_difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eO89S0ZOl5E",
        "outputId": "c5df4ad9-6c8b-40f2-811a-221e992ab6c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv('users.csv')  # Adjust the file name if needed\n",
        "\n",
        "# Calculate the correlation between 'followers' and 'public_repos'\n",
        "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Correlation between followers and public_repos: {correlation:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX6k3k6bVgHE",
        "outputId": "522eae2f-329c-4f6c-fc43-a05dcf5d9329"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between followers and public_repos: 0.051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data from CSV\n",
        "users_df = pd.read_csv(\"users.csv\")\n",
        "\n",
        "# Step 1: Handle empty emails by replacing empty strings with NaN\n",
        "users_df['email'] = users_df['email'].replace('', pd.NA)\n",
        "\n",
        "# Step 2: Separate users into hireable and non-hireable groups\n",
        "hireable_users = users_df[users_df['hireable'] == 'true']\n",
        "non_hireable_users = users_df[users_df['hireable'] == 'false']\n",
        "\n",
        "# Step 3: Count users with valid email addresses in each group\n",
        "hireable_with_email = hireable_users['email'].notna().sum()  # Count non-null emails for hireable\n",
        "non_hireable_with_email = non_hireable_users['email'].notna().sum()  # Count non-null emails for non-hireable\n",
        "\n",
        "# Step 4: Calculate the number of users in each group\n",
        "total_hireable_users = len(hireable_users)\n",
        "total_non_hireable_users = len(non_hireable_users)\n",
        "\n",
        "# Step 5: Calculate the fractions of users with email addresses\n",
        "fraction_hireable_with_email = (\n",
        "    hireable_with_email / total_hireable_users if total_hireable_users > 0 else 0\n",
        ")\n",
        "fraction_non_hireable_with_email = (\n",
        "    non_hireable_with_email / total_non_hireable_users if total_non_hireable_users > 0 else 0\n",
        ")\n",
        "\n",
        "# Step 6: Calculate the difference in fractions\n",
        "email_difference = fraction_hireable_with_email - fraction_non_hireable_with_email\n",
        "\n",
        "# Step 7: Print the results rounded to three decimal places\n",
        "print(f\"Fraction of users with email when hireable = true: {fraction_hireable_with_email:.3f}\")\n",
        "print(f\"Fraction of users with email when hireable = false: {fraction_non_hireable_with_email:.3f}\")\n",
        "print(f\"Difference in email sharing: {email_difference:.3f}\")\n",
        "\n",
        "# Step 8: Validate the results\n",
        "if total_hireable_users == 0:\n",
        "    print(\"No hireable users found.\")\n",
        "if total_non_hireable_users == 0:\n",
        "    print(\"No non-hireable users found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHJhwlIQcjIc",
        "outputId": "0603c349-d87f-4061-f0cc-3d5e843387df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraction of users with email when hireable = true: 0.672\n",
            "Fraction of users with email when hireable = false: 0.000\n",
            "Difference in email sharing: 0.672\n",
            "No non-hireable users found.\n"
          ]
        }
      ]
    }
  ]
}